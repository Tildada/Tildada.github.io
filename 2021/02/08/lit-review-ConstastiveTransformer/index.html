<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="一、解决了什么问题使用Encoder-decoder模型目前还存在一些问题。RNN难以捕捉长距离依赖，易导致重要信息的丢失，难以处理较长文本。Seq2Seq模型可能会生成不准确的序列，产生意义上的矛盾。Given the sentence “The United States President Trump was raised in the borough of Queens in New Yo">
<meta property="og:type" content="article">
<meta property="og:title" content="lit review &quot;Contrastive Triple Extraction with Generative Transformer&quot;">
<meta property="og:url" content="http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/index.html">
<meta property="og:site_name" content="Wentao&#39;s Blog">
<meta property="og:description" content="一、解决了什么问题使用Encoder-decoder模型目前还存在一些问题。RNN难以捕捉长距离依赖，易导致重要信息的丢失，难以处理较长文本。Seq2Seq模型可能会生成不准确的序列，产生意义上的矛盾。Given the sentence “The United States President Trump was raised in the borough of Queens in New Yo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/images/ContrastiveTransformer1.jpg">
<meta property="og:image" content="http://yoursite.com/images/ContrastiveTransformer2.jpg">
<meta property="article:published_time" content="2021-02-08T14:19:16.000Z">
<meta property="article:modified_time" content="2021-02-09T22:58:36.094Z">
<meta property="article:author" content="Wentao Kang">
<meta property="article:tag" content="lit review">
<meta property="article:tag" content="Entity and Relation Extraction">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/ContrastiveTransformer1.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<meta name="generator" content="Hexo 5.0.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" href="/2021/02/08/lit-review-Effective-En-De/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&text=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&is_video=false&description=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;&body=Check out this article: http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&name=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&t=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%A7%A3%E5%86%B3%E4%BA%86%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">一、解决了什么问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="toc-number">2.</span> <span class="toc-text">二、如何解决</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%EF%BC%9A"><span class="toc-number">2.1.</span> <span class="toc-text">模型：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Triplet-Contrastive-Learning"><span class="toc-number">2.1.1.</span> <span class="toc-text">Triplet Contrastive Learning</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%88%86%E6%9E%90%E7%BB%93%E8%AE%BA"><span class="toc-number">3.</span> <span class="toc-text">三、分析结论</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Wentao's Blog</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-02-08T14:19:16.000Z" itemprop="datePublished">2021-02-08</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Entity-and-Relation-Extraction/" rel="tag">Entity and Relation Extraction</a>, <a class="tag-link-link" href="/tags/lit-review/" rel="tag">lit review</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="一、解决了什么问题"><a href="#一、解决了什么问题" class="headerlink" title="一、解决了什么问题"></a>一、解决了什么问题</h1><p>使用Encoder-decoder模型目前还存在一些问题。RNN难以捕捉长距离依赖，易导致重要信息的丢失，难以处理较长文本。Seq2Seq模型可能会生成不准确的序列，产生意义上的矛盾。Given the sentence “The United States President Trump was raised in the borough of Queens in New York City, and lived there until age 13,” the model could generate the fact “(Trump, born in, Queens).” 尽管逻辑上可能正确，但从原句无法找到直接证据支持。</p>
<h1 id="二、如何解决"><a href="#二、如何解决" class="headerlink" title="二、如何解决"></a>二、如何解决</h1><p>Seq2Seq，输入文本source，输出三元组target sequence。输出中，一次生成一个实体或关系或特殊字符，其中[SOS]和[EOS]表示target sequence的起始和终止，每个三元组间的分隔符为[S2S_SEQ]<br><img src="/images/ContrastiveTransformer1.jpg" alt="alt"></p>
<h2 id="模型："><a href="#模型：" class="headerlink" title="模型："></a>模型：</h2><p>Input Encoder 输入表示同Bert<br>Generative Transformer 12层Transformer Encoder。第l层Transformer的计算如下：<br><img src="/images/ContrastiveTransformer2.jpg" alt="alt"><br>训练时，输入文本和正确的目标三元组都会作为输入，mask matrices, M，在生成三元组时，利用partial causal masking，这样 source和target无法互相看到（和Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction类似）。</p>
<h3 id="Triplet-Contrastive-Learning"><a href="#Triplet-Contrastive-Learning" class="headerlink" title="Triplet Contrastive Learning"></a>Triplet Contrastive Learning</h3><p>为了让生成的三元组更加可信且忠于原文。进行mask设为全0的二分类，正样本为正确的三元组，负样本通过替换三元组的一个实体为随机token生成。将输入文本和一个三元组连接作为输入，取[CLS]计算分类的logits </p>
<p>triplet contrastive learning和triple generation是两个不同的任务，但是是同时进行的。如果训练时，两个任务遇到了同一个样本，那Generative模型就可以直接看到所有的token了。为解决这个问题，作者使用了 batch-wise dynamic attention masking，根据Bernoulli分布为生成任务取样，其余样本则去做contrastive learning。测试时，beam search生成三元组序列，triple-wise calibrating algorithm（contrastive learning score如果小于某一个阈值，则说明三元组不合理），制定规则（比如头实体之后应该是关系）</p>
<h1 id="三、分析结论"><a href="#三、分析结论" class="headerlink" title="三、分析结论"></a>三、分析结论</h1><ol>
<li>生成式模型的搜索空间比抽取式更大，所以生成式模型的优化难度比抽取式方法大，相比之下，生成式的方法更加灵活，抽取可以不仅限于实体关系领域，这对开放领域open domain 的信息抽取研究是有价值的。</li>
<li>随机初始化的模型依然能够有不错的表现，说明好的表现不仅来自于预训练语言模型，模型结构本身对结果提升的作用同样明显。</li>
<li>随着句子长度增加，所有模型f1 score都有下降，相比RNN-based CopyRE，论文中模型表现更好。</li>
<li>不平衡的学习使得模型倾向于将有相似上下文的样本归到那些有较高频率出现的关系中，但这样的结果有可能是错误的。</li>
<li>由于使用端到端的生成方法，在没有序列标记信息的情况下，识别实体边界是一个挑战。<br>数据集质量不高，存在噪声。</li>
</ol>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%A7%A3%E5%86%B3%E4%BA%86%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">一、解决了什么问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="toc-number">2.</span> <span class="toc-text">二、如何解决</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%EF%BC%9A"><span class="toc-number">2.1.</span> <span class="toc-text">模型：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Triplet-Contrastive-Learning"><span class="toc-number">2.1.1.</span> <span class="toc-text">Triplet Contrastive Learning</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%88%86%E6%9E%90%E7%BB%93%E8%AE%BA"><span class="toc-number">3.</span> <span class="toc-text">三、分析结论</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&text=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&is_video=false&description=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;&body=Check out this article: http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&title=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&name=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://yoursite.com/2021/02/08/lit-review-ConstastiveTransformer/&t=lit review &#34;Contrastive Triple Extraction with Generative Transformer&#34;"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2021
    Wentao Kang
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/projects_url">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


</body>
</html>
